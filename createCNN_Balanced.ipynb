{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1660455241050,"user":{"displayName":"xue leon","userId":"02123102598924872447"},"user_tz":-480},"id":"uW4Uy7HdW6uP","outputId":"a9645812-93a8-46d2-be2e-7732838044c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Aug 14 05:34:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   58C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19964,"status":"ok","timestamp":1661568369091,"user":{"displayName":"xue leon","userId":"02123102598924872447"},"user_tz":-480},"id":"mVcydMJiW726","outputId":"542681df-53f8-4296-cde2-0a2737970fa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","gdrive\tsample_data\n","/content/gdrive/My Drive/MalMem\n"," adasyn_tl_xgboost_balance.ipynb\n"," adasyn_tl_xgboost_balance_noRUS.ipynb\n"," adasyn_tl_xgboost_imbalanced.ipynb\n"," clf_readcsv.py\n"," CNN_MalMem_balance\n"," CNN_MalMem_imbalance\n"," createCNN_Balanced.ipynb\n"," createCNN_Balanced_noRUS.ipynb（副本）\n"," createCNN_Imbalanced.ipynb\n","'Dynamic Malware Analysis with Feature Engineering and Feature Learning.pdf'\n"," ensemble_major_imb.ipynb\n"," ensemble_major.ipynb\n"," Evaluate_PR_3Algorithms.ipynb\n"," Evaluate_PR_CNN.ipynb\n"," Evaluate_PR_Voting.ipynb\n"," evaluate_PR_xgboost.ipynb\n"," evaluation_MM.xlsx\n"," logs\n"," MalMem_Test_x.csv\n"," MalMem_Test_y.csv\n"," MalMem_Train_x.csv\n"," MalMem_Train_y.csv\n"," MalMem_x.csv\n"," MalMem_y.csv\n","'Malware Memory Analysis _ Datasets _ Canadian Institute for Cybersecurity _ UNB.mhtml'\n"," myXgb_adasyn_MalMem_imb.json\n"," myXgb_adasyn_MalMem.json\n"," Obfuscated-MalMem2022.csv\n"," Obfuscated-MalMem2022-excel.xlsx\n","'Obfuscated Malware Detection Using Deep Generative Model based on Global_Local Features - ScienceDirect.mhtml'\n"," output-cnn.docx\n"," output.docx\n","'output-voting - balance_new.docx'\n"," output-voting.docx\n"," output-xgboost.docx\n"," train_attack_type_num.txt\n"," VotingClassifier_MalMem_balance.pkl\n"," VotingClassifier_MalMem_imbalance.pkl\n"]}],"source":["from google.colab import drive\n","#drive.mount('/content/gdrive', force_remount=True)\n","drive.mount('/content/gdrive')\n","!ls\n","%cd gdrive/My\\ Drive/MalMem/\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFXtodO_swsx"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Jun  8 16:54:44 2022\n","\n","@author: Administrator\n","\"\"\"\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Oct  1 00:05:33 2021\n","create network\n","@author: Administrator\n","CNN neural network running\n","\"\"\"\n","\n","import time\n","import sys\n","start = time.time()\n","\n","#add tensorflow. before keras\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential  #序贯模型\n","from tensorflow.keras.layers import Dense    #全连接层\n","from tensorflow.keras.layers import Dropout  #随机失活层\n","from tensorflow.keras.layers import Flatten  #展平层，从卷积层到全连接层必须展平\n","from tensorflow.keras.layers import Conv1D   #卷积层\n","from tensorflow.keras.layers import MaxPooling1D  #最大值池化\n","import pandas as pd\n","from tensorflow.keras import backend as k\n","#from sklearn.cross_validation import train_test_split #随机划分为训练子集和测试子集\n","from sklearn.model_selection import train_test_split  #leon\n","#from keras.utils.vis_utils import plot_model #leon\n","from tensorflow.keras.utils import  plot_model  #leon\n","from tensorflow.keras.optimizers import SGD \n","import matplotlib.pyplot as plt\n","import pydot #leon\n","from tensorflow.keras.callbacks import TensorBoard\n","from sklearn import metrics\n","import tensorflow as tf\n","import numpy as np\n","from collections import Counter\n","\n","batch_size = 128  #一批训练样本128张图片\n","\n","num_classes = 4  # 总共4个类别\n","epochs = 40   #一共迭代20轮 epochs = 20   \n","log_folder = 'logs'\n","#class_names = ['benign 0', 'dos 1', 'probe 2', 'r2l 3', 'u2r 4']\n","#class_names = ['normal 0', 'dos 1', 'ddos 2', 'injection 3', 'xss 4','password 5','scanning 6', 'mitm 7']\n","c\n","\n","# x_train = pd.read_csv('KDDTrain_x.csv',header=None).values\n","# y_train = pd.read_csv('KDDTrain_y.csv',header=None).values\n","\n","#x_train = pd.read_csv('KDDTrain_x_20.csv',header=None)\n","#y_train = pd.read_csv('KDDTrain_y_20.csv',header=None)\n","\n","x_train = pd.read_csv('MalMem_x.csv',header=None)\n","y_train = pd.read_csv('MalMem_y.csv',header=None)\n","train_x, test_x, train_Y, test_Y = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n","\n","\"\"\"\n","train_x = pd.read_csv('MalMem_Train_x.csv',header=None)\n","train_Y = pd.read_csv('MalMem_Train_y.csv',header=None)\n","test_x = pd.read_csv('MalMem_Test_x.csv',header=None)\n","test_Y = pd.read_csv('MalMem_Test_y.csv',header=None)\n","\"\"\"\n","\n","#y_train[0]=list(y_train[0].map({'benign':0, 'dos':1, 'probe':2, 'r2l':3, 'u2r':4}))\n","print(\"train_x\", train_x.head())\n","print(\"train_Y\", train_Y.head())\n","\n","#y_train = y_train.values.ravel()\n","train_Y = train_Y.values.ravel()\n","test_Y  = test_Y.values.ravel()\n","# sys.exit(0)\n","\n","print(\"before oversampling \\n\", pd.Series(train_Y).value_counts())\n","# td_train = pd.read_csv('KDDTest_x.csv',header=None)\n","# td_target = pd.read_csv('KDDTest_y.csv',header=None)\n","\n","# x_test = pd.read_csv('KDDTest_x.csv',header=None).values\n","# y_test = pd.read_csv('KDDTest_y.csv',header=None).values\n","#x_test = pd.read_csv('KDDTest_x_20.csv',header=None)\n","#y_test = pd.read_csv('KDDTest_y_20.csv',header=None)\n","#y_test[0]=list(y_test[0].map({'benign':0, 'dos':1, 'probe':2, 'r2l':3, 'u2r':4}))\n","#print(\"x_test\", x_test.head())\n","#print(\"y_test\", y_test.head())\n","#y_test = y_test.values.ravel()\n","# sys.exit(0)\n","\n","######--------------- RandomUnderSampler-------------------------\n","mean_class_size = int(pd.Series(train_Y).value_counts().sum()/4)\n","print(\"mean_class_size\", mean_class_size)\n","ratio= {0: mean_class_size\n","        #'dos': mean_class_size,\n","        #'probe': mean_class_size,\n","        #'r2l': mean_class_size,\n","        #'u2r': mean_class_size\n","        }\n","# check if ratio para is still used\n","# print(\"before \\n\", pd.Series(train_Y).value_counts())\n","print('Original dataset shape %s' % Counter(train_Y))\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","rus = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n","train_x, train_Y = rus.fit_resample(train_x, train_Y)\n","print('now dataset shape %s' % Counter(train_Y))\n","\n","#*******try using ADASYN on train dataset to make balance\n","#only \n","from imblearn.over_sampling import ADASYN\n","ad = ADASYN (sampling_strategy='not majority', random_state=0)\n","# train_x_sm, train_Y_sm = sm.fit_resample(train_x, train_Y)\n","train_x_ad, train_Y_ad = ad.fit_resample(train_x, train_Y)\n","print('adasyn dataset shape %s' % Counter(train_Y_ad))\n","\n","#Tomek Links\n","from imblearn.under_sampling import TomekLinks\n","sampling_strategy = \"all\"\n","tl = TomekLinks(sampling_strategy=sampling_strategy)\n","# x_res, Y_res = tl.fit_resample(train_x_sm, train_Y_sm)\n","x_res, Y_res = tl.fit_resample(train_x_ad, train_Y_ad)\n","print('Tomek Links dataset shape %s' % Counter(Y_res))\n","#*************************\n","\n","\n","#从训练集中手动指定验证集\n","# x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.15, random_state=2)\n","#input_shape = (41, 1)\n","\n","# print(\"shape\", x_train.shape[0])\n","# print(\"shape\", x_dev.shape[0])\n","\n","# create confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2337,"status":"ok","timestamp":1660455516182,"user":{"displayName":"xue leon","userId":"02123102598924872447"},"user_tz":-480},"id":"ftTwoSt4s6rl","outputId":"78a8d41f-d026-429a-acf0-4c692d533422"},"outputs":[{"output_type":"stream","name":"stdout","text":["(50, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["{'amsgrad': False,\n"," 'beta_1': 0.9,\n"," 'beta_2': 0.999,\n"," 'decay': 0.0,\n"," 'epsilon': 1e-07,\n"," 'learning_rate': 0.001,\n"," 'name': 'Adam'}"]},"metadata":{},"execution_count":5}],"source":["import itertools \n","import io\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.optimizers import Adam\n","#from tensorflow.keras.optimizers import SGD\n","\n","def plot_confusion_matrix(cm, class_names): \n","    figure = plt.figure(figsize=(8, 8)) \n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent) \n","    plt.title(\"Confusion matrix\") \n","    plt.colorbar() \n","    tick_marks = np.arange(len(class_names)) \n","    plt.xticks(tick_marks, class_names, rotation=45) \n","    plt.yticks(tick_marks, class_names)\n","\n","    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)  \n","    threshold = cm.max() / 2. \n","\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):   \n","        color = \"white\" if cm[i, j] > threshold else \"black\"   \n","        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)  \n","    \n","    plt.tight_layout() \n","    plt.ylabel('True label') \n","    plt.xlabel('Predicted label') \n","\n","    return figure\n","\n","def plot_to_image(figure):    \n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='png')\n","    plt.close(figure)\n","    buf.seek(0)\n","\n","    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n","    digit = tf.expand_dims(digit, 0)\n","\n","    return digit\n","\n","def log_confusion_matrix(epoch, logs):\n","    predictions = model.predict(test_x)\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    cm = metrics.confusion_matrix(test_Y, predictions)\n","    figure = plot_confusion_matrix(cm, class_names=class_names)\n","    cm_image = plot_to_image(figure)\n","    \n","    with file_writer_cm.as_default():\n","        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n","\n","file_writer_cm = tf.summary.create_file_writer(log_folder)\n","#**********************************\n","\n","\n","if k.image_data_format() == 'channels_first':\n","\n","   x_train_p = x_res.values.reshape(x_res.shape[0], 1, 50)\n","   test_x = test_x.values.reshape(test_x.shape[0], 1, 50)\n","   input_shape = (1, 50)\n","else:\n","\n","   x_train_p = x_res.values.reshape(x_res.shape[0], 50, 1)\n","   test_x = test_x.values.reshape(test_x.shape[0], 50, 1)\n","   input_shape = (50, 1)\n","  \n","print(input_shape)\n","#x_train.head(5)\n","\n","\n","model = Sequential()  #sequential序贯模型:多个网络层的线性堆叠\n","#输出的维度（卷积滤波器的数量）filters=32；1D卷积窗口的长度kernel_size=3；激活函数activation   模型第一层需指定input_shape：\n","model.add(Conv1D(32, 3, activation='relu',input_shape=input_shape))  #data_format默认channels_last\n","model.add(MaxPooling1D(pool_size=(2))) #池化层：最大池化  池化窗口大小pool_size=2\n","model.add(Flatten())  #展平一个张量，返回一个调整为1D的张量\n","#model.add(Dropout(0.25))  #需要丢弃的输入比例=0.25    dropout正则化-减少过拟合  影响不大\n","model.add(Dense(128, activation='relu',name='fully_connected')) #全连接层\n","model.add(Dense(num_classes, activation='softmax',name='softmax'))\n","\n","#编译，损失函数:多类对数损失，用于多分类问题， 优化函数：adadelta， 模型性能评估是准确率\n","#binary classification\n","#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n","#model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n","#multiclassification\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n","#model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy']) \n","\n","#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy']) \n","#运行 ， verbose=1输出进度条记录 0-不输出      epochs训练的轮数     batch_size:指定进行梯度下降时每个batch包含的样本数\n","#model.fit(x_train, y_train, batch_size= batch_size, epochs=epochs, verbose=1)\n","\n","model.optimizer.get_config()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBz7D1LcW78U"},"outputs":[],"source":["\n","\n","\n","%reload_ext tensorboard\n","\n","callbacks = [\n","   TensorBoard(log_dir=log_folder, \n","               histogram_freq=1, \n","               write_graph=True,\n","               write_images=True,\n","               update_freq='epoch',\n","               profile_batch=2,\n","               embeddings_freq=1),\n","   keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n","]\n","\n","\"\"\"\n","callbacks = [TensorBoard(log_dir=log_folder,\n","                         histogram_freq=1,\n","                         write_graph=True,\n","                         write_images=True,\n","                         update_freq='epoch',\n","                         profile_batch=2,\n","                         embeddings_freq=1)]\n","\"\"\"\n","history = model.fit(x_train_p, Y_res, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(test_x, test_Y),\\\n","                    callbacks=callbacks)\n","\n","\n","#原程序也注释的部分\n","#模型的训练损失（loss）和验证损失（val_loss），以及训练准确率（acc）和验证准确率（val_acc）可以使用绘图代码绘制出来\n","def smooth_curve(points,factor=0.8): #定义使曲线变得平滑\n","    smoothed_points = []\n","    for point in points:\n","        if smoothed_points:\n","            previous = smoothed_points[-1]\n","            smoothed_points.append(previous * factor + point * (1 - factor))\n","        else:\n","            smoothed_points.append(point)\n","    return smoothed_points\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs,loss, 'bo', label = 'Training loss')\n","plt.plot(epochs,val_loss, 'b', label = 'Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.figure()\n","\n","acc = history.history['accuracy'] \n","#acc = history.history['sparse_categorical_accuracy'] \n","\n","val_acc = history.history['val_accuracy'] \n","#val_acc = history.history['val_sparse_categorical_accuracy'] \n","\n","plt.plot(epochs, acc,'bo', label = 'Training acc')\n","plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.show()\n","\n","\n","# 将测试集输入到训练好的模型中，查看测试集的误差\n","#score = model.evaluate(x_test, y_test, verbose=0,batch_size= batch_size)\n","score = model.evaluate(test_x, test_Y, verbose=0, batch_size= batch_size)\n","print('Validation loss:', score[0])\n","print('Validation accuracy: %.6f%%' % (score[1] * 100))\n","\n","#model.save('CNN-test-data-balanced-dropout')  #dropout\n","model.save('CNN_MalMem_balance')\n","#results = confusion_matrix(test_Y, pred_Y, labels= clf.classes_)\n","#print results\n","\n","\n","# use testdata to test the model\n","# score2 = model.evaluate(td_train, td_target, verbose=0, batch_size= batch_size)\n","# print('Testdata loss:', score2[0])\n","# print('Testdata accuracy: %.2f%%' % (score2[1] * 100))\n","%tensorboard --logdir={log_folder}\n","\n","#运行的时间\n","stop = time.time()\n","print(str(stop-start) + \"秒\")\n","\n","# 神经网络可视化\n","#plot_model(model, to_file='D:/model-nslkdd.png',show_shapes=True)\n","\n","#输出模型各层参数情况\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SSDrIUzUYrA"},"outputs":[],"source":["from imblearn.metrics import geometric_mean_score, classification_report_imbalanced\n","from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score, \\\n","    classification_report, roc_auc_score, roc_curve, auc, plot_confusion_matrix, ConfusionMatrixDisplay\n","\n","class_names_num = ['0', '1', '2', '3']\n","predictions = model.predict(test_x)\n","print(\"predictions shape:\", predictions.shape)\n","print(predictions)\n","\n","classes = np.argmax(predictions, axis = 1)\n","print(\"classes:\", classes)\n","\n","print(classification_report(test_Y, classes, target_names=class_names))   #Y_res\n","print(classification_report_imbalanced(test_Y, classes, digits=4, target_names=class_names))  #Y_res\n","print(f\"The geometric mean is {geometric_mean_score(test_Y, classes):.3f}\") #Y_res\n","\n","\n","#y_test = y_test.values.ravel()\n","#cm = confusion_matrix(y_test, classes, labels=class_names_num)\n","cm = confusion_matrix(test_Y, classes)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names_num)\n","disp.plot()\n","_ = disp.ax_.set_title(\"CNN\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P14861K3V33H","executionInfo":{"status":"ok","timestamp":1660455996589,"user_tz":-480,"elapsed":16470,"user":{"displayName":"xue leon","userId":"02123102598924872447"}},"outputId":"6f20c8b4-b38e-49a3-c632-93f5e73ed2a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROC AUC Score: 0.9423714027407903\n"]}],"source":["rac = roc_auc_score(test_Y, predictions, multi_class='ovr', average ='macro')  #Y_res\n","print(\"ROC AUC Score:\", rac)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-27_hYkaqcSL"},"outputs":[],"source":["# plot roc curve\n","from itertools import cycle\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import label_binarize\n","from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score, \\\n","    classification_report, roc_auc_score, roc_curve, auc, plot_confusion_matrix, ConfusionMatrixDisplay\n","\n","y = label_binarize(test_Y, classes=[0, 1, 2, 3])  #Y_res\n","n_classes = y.shape[1]\n","predictions = model.predict(test_x)\n","yy = predictions\n","\n","print(\"y:\", y)\n","print(\"n_classes:\", n_classes)\n","\n","lw = 3\n","\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    # fpr[i], tpr[i], _ = roc_curve(Y_res[:, i], y[:, i])\n","    # fpr[i], tpr[i], threshold = roc_curve(y[:, i], yy[:, i], pos_label=0)\n","    fpr[i], tpr[i], threshold = roc_curve(y[:, i], yy[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), yy.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","\n","# First aggregate all false positive rates\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","# Then interpolate all ROC curves at this points\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","\n","# Finally average it and compute AUC\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","# Plot all ROC curves\n","plt.figure()\n","plt.plot(\n","    fpr[\"micro\"],\n","    tpr[\"micro\"],\n","    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n","    color=\"deeppink\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","\n","plt.plot(\n","    fpr[\"macro\"],\n","    tpr[\"macro\"],\n","    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n","    color=\"navy\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","\n","\n","colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"#FF6666\"]) #, \"green\", \"yellow\", \"slategray\", \"blueviolet\"])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(\n","        fpr[i],\n","        tpr[i],\n","        color=color,\n","        lw=lw,\n","        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n","    )\n","\n","plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"Receiver operating characteristic of CNN multiclass\")\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","\n","# compute roc_auc_score\n","# y_prob = classifier.predict_proba(X_test)\n","\n","macro_roc_auc_ovo = roc_auc_score(test_Y, yy, multi_class=\"ovo\", average=\"macro\")  #Y_res\n","weighted_roc_auc_ovo = roc_auc_score(\n","    test_Y, yy, multi_class=\"ovo\", average=\"weighted\"\n",")\n","macro_roc_auc_ovr = roc_auc_score(test_Y, yy, multi_class=\"ovr\", average=\"macro\")\n","weighted_roc_auc_ovr = roc_auc_score(\n","    test_Y, yy, multi_class=\"ovr\", average=\"weighted\"\n",") #Y_res\n","print(\n","    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n","    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",")\n","print(\n","    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n","    \"(weighted by prevalence),\\n{:.6f}\"   #leon\n","    \"(micro)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr, roc_auc[\"micro\"])  #leon\n","    #\"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNAuWNTiSpnwfHqxbFPGnJK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}