{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adasyn_xgboost_fulldata_balance.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqqm360WNz8n4IX3UgkXmv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-in2bYWHK-Y","executionInfo":{"status":"ok","timestamp":1660615702246,"user_tz":-480,"elapsed":9,"user":{"displayName":"xue leon","userId":"02123102598924872447"}},"outputId":"b631d159-f15e-471a-c895-bd12f9199ed2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 16 02:08:22 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["CNN on full data"],"metadata":{"id":"ZavDffRPoyLO"}},{"cell_type":"markdown","source":["ADASYN+Tomek Link+XGBoost to balance data"],"metadata":{"id":"ksOy0_5tJwY_"}},{"cell_type":"code","source":["from google.colab import drive\n","#drive.mount('/content/gdrive', force_remount=True)\n","drive.mount('/content/gdrive')\n","!ls\n","%cd gdrive/My\\ Drive/phd-thesis/\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XVulxTeHLc5","executionInfo":{"status":"ok","timestamp":1660615728395,"user_tz":-480,"elapsed":22299,"user":{"displayName":"xue leon","userId":"02123102598924872447"}},"outputId":"bb617e52-09b0-430e-ef22-174f8f7793c8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","gdrive\tsample_data\n","/content/gdrive/My Drive/phd-thesis\n"," adasyn_TL_MajorVoting_balance.ipynb\n"," ADASYN_TL_MajorVoting_imb.ipynb\n"," adasyn_xgboost_20_imb.ipynb\n"," adasyn_xgboost_20.ipynb\n"," adasyn_xgboost_fulldata_balance.ipynb\n"," adasyn_xgboost_fulldata_imb.ipynb\n"," Attack_Types.csv\n","'bagging&ensemble.py'\n"," cnn.ipynb\n"," CNN-test-data\n"," CNN-test-data-balanced\n"," CNN-test-data-balanced-dropout\n"," CNN-test-data-imb\n"," createCNN_Balanced_fulldata.ipynb\n"," createCNN_Balanced.ipynb\n"," createNetwork-211025.py\n"," createNetwork-CNN-imb.ipynb\n","'createNetwork-testdata (1).ipynb'\n"," createNetwork-testdata.ipynb\n"," createNetwork-testdata.py\n"," ensemble_balance-old.ipynb\n"," ensemble_imb-old.ipynb\n"," Evaluate_adasyn_xgboost_model_fulldata.ipynb\n"," Evaluate_adasyn_xgboost_model_fulldata.ipynb（副本）\n"," Evaluate_adasyn_xgboost_model.ipynb\n"," evaluate_auc_3Algorithm_macro.ipynb\n"," evaluate_auc_3Algorithm_micro.ipynb\n"," Evaluate_CNN_Balacanced.ipynb\n"," Evaluate_CNN_imb.ipynb\n"," Evaluate_PR_3Algorithms.ipynb\n"," Evaluate_PR_CNN.ipynb\n"," Evaluate_PR_Voting.ipynb\n"," evaluate_PR_xgboost.ipynb\n"," evaluate_ros_balanced.ipynb\n"," Evaluate_voting_classifier_imb.ipynb\n"," Evaluate_voting_classifier.ipynb\n"," Field_Names.csv\n"," intrusion-detection-classification-by-jinner.ipynb\n"," KDDTest+.csv\n"," KDDTest_x_20.csv\n"," KDDTest_x.csv\n"," KDDTest_x_num.csv\n"," KDDTest_y_20.csv\n"," KDDTest_y.csv\n"," KDDTrain+.csv\n"," KDDTrain_x_20.csv\n"," KDDTrain_x.csv\n"," KDDTrain_x_num.csv\n"," KDDTrain_y_20.csv\n"," KDDTrain_y.csv\n"," load_xgbModel.ipynb\n"," logs\n"," MySSL.py\n"," myXgb_adasyn_imb.json\n"," myXgb_adasyn.json\n"," myXgb_imb.json\n"," myXgb.json\n"," myXgbModel.pkl\n"," myXgb_No_adasyn.json\n"," myXgb_ros.json\n"," prehandle-1009.py\n"," RUS-20.py\n"," smote-test.ipynb\n"," test_2.csv\n"," test_data.csv\n"," testdata_target.csv\n"," testdata_train.csv\n"," test_RandomOverSampler_xgboost.ipynb\n"," test-vc.ipynb\n"," test_xgboost-evaluaton.ipynb\n"," test_xgboost_nsl_kdd.ipynb\n"," train_2.csv\n"," train_2.rar\n"," Train_data.csv\n"," Untitled0.ipynb\n"," Untitled1.ipynb\n"," VotingClassifier-imb.pkl\n"," VotingClassifier.pkl\n"," xgboost_test_imb.ipynb\n"," xgboost_test.ipynb\n"]}]},{"cell_type":"code","source":["pip install --upgrade xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tco1ygNHUt89","executionInfo":{"status":"ok","timestamp":1660615756048,"user_tz":-480,"elapsed":21011,"user":{"displayName":"xue leon","userId":"02123102598924872447"}},"outputId":"7b7c1545-f555-453d-a199-a2413b64b7cd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Collecting xgboost\n","  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n","\u001b[K     |████████████████████████████████| 192.9 MB 83 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Installing collected packages: xgboost\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","Successfully installed xgboost-1.6.1\n"]}]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Jun  8 10:12:36 2022\n","using ADASYN and tomek link, and xgboost\n","with 20% dataset\n","balanced data model on test data\n","@author: Administrator\n","\"\"\"\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import confusion_matrix, zero_one_loss, classification_report, \\\n","    plot_confusion_matrix\n","    \n","\n","from collections import Counter\n","from sklearn.metrics import accuracy_score\n","import sys\n","from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n","import xgboost as xgb\n","import multiprocessing\n","import joblib\n","\n","\n","#traing dataset\n","# train_x = pd.read_csv('KDDTrain_x_20.csv',header=None, nrows=1000)\n","# train_Y = pd.read_csv('KDDTrain_y_20.csv',header=None, nrows=1000)\n","train_x = pd.read_csv('KDDTrain_x.csv',header=None)\n","train_Y = pd.read_csv('KDDTrain_y.csv',header=None)\n","train_x.drop(train_x.columns[[115,116,117]], axis=1, inplace=True)\n","train_Y[0]=list(train_Y[0].map({'benign':0, 'dos':1, 'probe':2, 'r2l':3, 'u2r':4}))\n","\n","print(\"train_x\", train_x.head())\n","print(\"train_y\", train_Y.head())\n","\n","#use few dataset to test \n","# train_x = train_x.head()\n","# train_Y = train_x.head()\n","\n","# train and test data split\n","# x_train, x_test, y_train, y_test = train_test_split( \\\n","     # train_x, train_Y, test_size=0.3, random_state=42)\n","\n","\n","#testing dataset\n","test_x = pd.read_csv('KDDTest_x.csv',header=None)\n","test_Y = pd.read_csv('KDDTest_y.csv',header=None)\n","test_x.drop(test_x.columns[[115,116,117]], axis=1, inplace=True)\n","test_Y[0]=list(test_Y[0].map({'benign':0, 'dos':1, 'probe':2, 'r2l':3, 'u2r':4}))\n","print(\"test_x\", test_x.head())\n","print(\"test_y\", test_Y.head())\n","\n","# train_Y = train_Y.values.ravel()\n","# test_Y  = test_Y.values.ravel()\n","# print('Original dataset shape %s' % Counter(train_Y))\n","\n","train_Y = train_Y.values.ravel()\n","test_Y  = test_Y.values.ravel()\n","print('Original train dataset shape %s' % Counter(train_Y))\n","print('Original test dataset shape %s' % Counter(test_Y))\n","\n","######--------------- RandomUnderSampler-------------------------\n","mean_class_size = int(pd.Series(train_Y).value_counts().sum()/5)\n","print(\"mean_class_size\", mean_class_size)\n","\n","ratio= {0: mean_class_size,\n","        1: mean_class_size\n","        #'probe': mean_class_size,\n","        #'r2l': mean_class_size,\n","        #'u2r': mean_class_size\n","        }\n","\n","# check if ratio para is still used\n","# print(\"before \\n\", pd.Series(train_Y).value_counts())\n","# print('Original dataset shape %s' % Counter(train_Y))\n","\n","#from imblearn.under_sampling import RandomUnderSampler\n","rus = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n","train_x, train_Y = rus.fit_resample(train_x, train_Y)\n","print('now dataset shape %s' % Counter(train_Y))\n","\n","\n","# #only smote\n","# from imblearn.over_sampling import SMOTE\n","# sm = SMOTE (sampling_strategy='auto', random_state=0)\n","# # train_x_sm, train_Y_sm = sm.fit_resample(train_x, train_Y)\n","# train_x_sm, train_Y_sm = sm.fit_resample(train_x, train_Y)\n","# print('smote dataset shape %s' % Counter(train_Y_sm))\n","\n","#*******try using ADASYN on test dataset to make balance\n","#only \n","from imblearn.over_sampling import ADASYN\n","ad = ADASYN (sampling_strategy='not majority', random_state=0)\n","# train_x_sm, train_Y_sm = sm.fit_resample(train_x, train_Y)\n","train_x_ad, train_Y_ad = ad.fit_resample(train_x, train_Y)\n","print('adasyn dataset shape %s' % Counter(train_Y_ad))\n","\n","#Tomek Links\n","from imblearn.under_sampling import TomekLinks\n","sampling_strategy = \"all\"\n","tl = TomekLinks(sampling_strategy=sampling_strategy)\n","# x_res, Y_res = tl.fit_resample(train_x_sm, train_Y_sm)\n","x_res, Y_res = tl.fit_resample(train_x_ad, train_Y_ad)\n","print('Tomek Links dataset shape %s' % Counter(Y_res))\n","\n","#sys.exit(0)\n","\n","### ENN\n","# from imblearn.under_sampling import EditedNearestNeighbours\n","# sampling_strategy = \"not minority\"\n","# enn = EditedNearestNeighbours(sampling_strategy=sampling_strategy)\n","# x_res, y_res = enn.fit_resample(train_x_sm, train_Y_sm)\n","# print('ENN dataset shape %s' % Counter(y_res))\n","\n","\n","\n","\"\"\"######--------------- RandomUnderSampler-------------------------\n","mean_class_size = int(pd.Series(train_Y).value_counts().sum()/5)\n","print(\"mean_class_size\", mean_class_size)\n","\n","ratio= {'benign': mean_class_size,\n","        'dos': mean_class_size,\n","        'probe': mean_class_size,\n","        'r2l': mean_class_size,\n","        'u2r': mean_class_size\n","        }\n","\n","# check if ratio para is still used\n","# print(\"before \\n\", pd.Series(train_Y).value_counts())\n","print('Original dataset shape %s' % Counter(train_Y))\n","\n","rus = RandomUnderSampler(sampling_strategy=ratio, random_state=0)\n","train_x_rus, train_Y_rus = rus.fit_resample(train_x, train_Y)\n","\n","print('now dataset shape %s' % Counter(train_Y_rus))\n","\"\"\"\n","\"\"\"\n","# decision tree clf\n","classifier = DecisionTreeClassifier(random_state=17)\n","classifier.fit(x_res, Y_res)\n","\n","# pred_y = classifier.predict(test_x)\n","# results = confusion_matrix(test_Y, pred_y)\n","# error = zero_one_loss(test_Y, pred_y)\n","\n","pred_y = classifier.predict(x_test)\n","results = confusion_matrix(y_test, pred_y)\n","error = zero_one_loss(y_test, pred_y)\n","\"\"\"\n","\n","#***xgboost clf\n","#xgb_model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count() // 2)\n","#xgb_model = xgb.XGBClassifier(n_jobs=1).fit(x_res, Y_res)\n","#kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n","# xgb_model = xgb.XGBClassifier(objective='multi:softmax')\n","\n","xgb_model = xgb.XGBClassifier()\n","# clf = GridSearchCV(xgb_model, {'max_depth': [2, 4, 6],\n","#                                y'n_estimators': [50, 100, 200]}, verbose=1,\n","#                                n_jobs=2)\n","# param_grid = [\n","#     {'max_depth': [2, 4, 6], 'n_estimators': [50, 100, 200]}, \n","#     {'objective': ['multi:softmax'], 'verbose': [1], 'n_jobs':[-1]},\n","#     ]\n","    \n","param_grid = [\n","    {'max_depth': [6], 'n_estimators': [200]}, \n","    {'objective': ['multi:softprob'], 'num_class': [5], 'verbose': [1], 'n_jobs':[-1]},\n","    ]\n","    \n","\n","# clf = GridSearchCV(xgb_model, {'max_depth': [2, 4, 6],\n","#                                'n_estimators': [50, 100, 200]}, verbose=1,\n","#                                 n_jobs=-1)\n","# clf = GridSearchCV(xgb_model, param_grid, cv=2)\n","clf = GridSearchCV(xgb_model, param_grid, cv=5)\n","\n","clf.fit(x_res, Y_res)\n","\n","# save xgboost model\n","clf.best_estimator_.save_model('myXgb_adasyn.json')\n","\n","print(clf.best_score_)\n","print(clf.best_params_)\n","\n","\n","\n","\n","#evaluation with no sampling on test data\n","#pred_y = xgb_model.predict(x_test)\n","pred_y = clf.predict(test_x)\n","results = confusion_matrix(test_Y, pred_y)\n","error = zero_one_loss(test_Y, pred_y)\n","target_names = ['benign 0', 'dos 1', 'probe 2', 'r2l 3', 'u2r 4']\n","\n","print(\"test result: \\n\" , results)\n","print(\"test error:\", error)\n","# print(\"validation:\", accuracy_score(test_Y, pred_y))\n","print(\"test validation:\", accuracy_score(test_Y, pred_y))\n","print(classification_report(test_Y, pred_y, target_names=target_names))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VI-vNqQ3HLmx","executionInfo":{"status":"ok","timestamp":1660618558810,"user_tz":-480,"elapsed":2798413,"user":{"displayName":"xue leon","userId":"02123102598924872447"}},"outputId":"e6de5cdb-5d7b-4aa4-a3bb-e5bdbc9b7e86"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["train_x         0         1         2    3         4         5         6         7    \\\n","0 -0.110249 -0.007679 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","1 -0.110249 -0.007737 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","2 -0.110249 -0.007762 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","3 -0.110249 -0.007723 -0.002891    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","4 -0.110249 -0.007728 -0.004814    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","\n","   8         9    ...  105  106  107  108  109  110  111  112  113  114  \n","0    0 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","1    0 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","2    0 -0.011664  ...    0    0    0    0    0    0    0    1    0    0  \n","3    1 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","4    1 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","\n","[5 rows x 115 columns]\n","train_y    0\n","0  0\n","1  0\n","2  1\n","3  0\n","4  0\n","test_x         0         1         2    3         4         5         6         7    \\\n","0 -0.110249 -0.007762 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","1 -0.110249 -0.007762 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","2 -0.109481 -0.005551 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","3 -0.110249 -0.007759 -0.004919    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","4 -0.109865 -0.007762 -0.004915    0 -0.089486 -0.007736 -0.095076 -0.027023   \n","\n","   8         9    ...  105  106  107  108  109  110  111  112  113  114  \n","0    0 -0.011664  ...    0    0    0    1    0    0    0    0    0    0  \n","1    0 -0.011664  ...    0    0    0    1    0    0    0    0    0    0  \n","2    0 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","3    0 -0.011664  ...    0    0    0    0    0    0    0    0    0    0  \n","4    0 -0.011664  ...    0    0    0    0    1    0    0    0    0    0  \n","\n","[5 rows x 115 columns]\n","test_y    0\n","0  1\n","1  1\n","2  0\n","3  2\n","4  2\n","Original train dataset shape Counter({0: 67343, 1: 45927, 2: 11656, 3: 995, 4: 52})\n","Original test dataset shape Counter({0: 9711, 1: 7636, 3: 2574, 2: 2423, 4: 200})\n","mean_class_size 25194\n","now dataset shape Counter({0: 25194, 1: 25194, 2: 11656, 3: 995, 4: 52})\n","adasyn dataset shape Counter({2: 25208, 0: 25194, 1: 25194, 4: 25193, 3: 25157})\n","Tomek Links dataset shape Counter({2: 25208, 4: 25192, 1: 25189, 0: 25186, 3: 25155})\n","[02:38:08] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[02:41:02] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[02:43:53] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[02:46:46] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[02:49:35] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[02:52:24] WARNING: ../src/learner.cc:627: \n","Parameters: { \"verbose\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","0.9912649884856666\n","{'n_jobs': -1, 'num_class': 5, 'objective': 'multi:softprob', 'verbose': 1}\n","test result: \n"," [[9426   64  215    4    2]\n"," [1152 6236  248    0    0]\n"," [ 313  166 1944    0    0]\n"," [2072    0   40  451   11]\n"," [ 161    0   12   13   14]]\n","test error: 0.19841199432221435\n","test validation: 0.8015880056777857\n","              precision    recall  f1-score   support\n","\n","    benign 0       0.72      0.97      0.83      9711\n","       dos 1       0.96      0.82      0.88      7636\n","     probe 2       0.79      0.80      0.80      2423\n","       r2l 3       0.96      0.18      0.30      2574\n","       u2r 4       0.52      0.07      0.12       200\n","\n","    accuracy                           0.80     22544\n","   macro avg       0.79      0.57      0.59     22544\n","weighted avg       0.84      0.80      0.78     22544\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"oaWYOifDUrXP"},"execution_count":null,"outputs":[]}]}