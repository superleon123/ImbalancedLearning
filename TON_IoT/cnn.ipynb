{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMu9ugi6DG2q+xHKz3zAAuy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9W45upbfUvL7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk3vq1ma-Xo_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636643467156,"user_tz":-480,"elapsed":17,"user":{"displayName":"xue leon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02123102598924872447"}},"outputId":"f2659147-5f08-4634-f975-1cdf77689dee"},"source":["!nvidia-smi\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Nov 11 15:11:06 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"NbncYSkNVUzl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635323709226,"user_tz":-480,"elapsed":24982,"user":{"displayName":"xue leon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02123102598924872447"}},"outputId":"31ff0789-a32b-4816-d0ad-1cbd199ddf40"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls\n","%cd gdrive/My\\ Drive/TFKeras/\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n","\n","Enter your authorization code:\n","4/1AX4XfWj1hh0I9qQuJubRRAfOqt-xKAdvFuSom4-5QkkynahJRXqdFUI9r4M\n","Mounted at /content/gdrive\n","gdrive\tsample_data\n","/content/gdrive/My Drive/TFKeras\n","began\t      chap3.ipynb   chap6_a.ipynb  chap9.ipynb\tmodel\n","chap10.ipynb  chap4.ipynb   chap6_b.ipynb  data\t\tmodels\n","chap11.ipynb  chap5-cnn.py  chap7.ipynb    img\t\t__pycache__\n","chap12.ipynb  chap5.ipynb   chap8.ipynb    logs\t\tutils.py\n"]}]},{"cell_type":"code","metadata":{"id":"JCdgxCEIVIFM","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"error","timestamp":1635323636420,"user_tz":-480,"elapsed":4226,"user":{"displayName":"xue leon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02123102598924872447"}},"outputId":"fa9d4508-1357-4e01-b7ad-d8b41f8d0575"},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Oct  1 00:05:33 2021\n","create network\n","@author: Administrator\n","\"\"\"\n","import time \n","start = time.time()\n","\n","#add tensorflow. before keras\n","import keras\n","from tensorflow.keras.models import Sequential  #序贯模型\n","from tensorflow.keras.layers import Dense    #全连接层\n","from tensorflow.keras.layers import Dropout  #随机失活层\n","from tensorflow.keras.layers import Flatten  #展平层，从卷积层到全连接层必须展平\n","from tensorflow.keras.layers import Conv1D   #卷积层\n","from tensorflow.keras.layers import MaxPooling1D  #最大值池化\n","import pandas as pd\n","from tensorflow.keras import backend as k\n","#from sklearn.cross_validation import trainbuzhiyunyun_test_split #随机划分为训练子集和测试子集\n","from sklearn.model_selection import train_test_split  #leon\n","#from keras.utils.vis_utils import plot_model #leon\n","from tensorflow.keras.utils import  plot_model  #leon\n","from tensorflow.keras.optimizers import SGD \n","import matplotlib.pyplot as plt\n","import pydot #leon\n","\n","batch_size = 128  #一批训练样本128张图片\n","num_classes = 40  #有40个类别\n","epochs = 2   #一共迭代12轮\n","\n","# x_train = pd.read_csv('train_xe.csv',header=None).values\n","# y_train = pd.read_csv('train_ye.csv',header=None).values\n","\n","# x_train = pd.read_csv('train_xe.csv',header=None)\n","# y_train = pd.read_csv('train_ye.csv',header=None)\n","\n","x_train = pd.read_csv('train_2.csv',header=None)\n","y_train = pd.read_csv('test_2.csv',header=None)\n","\n","\n","print(\"x_train\", x_train.head())\n","print(\"y_train\", y_train.head())\n","\n","# x_test = pd.read_csv('test_x.csv',header=None).values\n","# y_test = pd.read_csv('test_y.csv',header=None).values\n","\n","# X = x_train.iloc[:, 1:42]\n","# Y = y_train.iloc[:, 0]\n","\n","#从训练集中手动指定验证集\n","X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.15, random_state=2)\n","\"\"\"\n","print(\"shape\", x_train.shape[0])\n","if k.image_data_format() == 'channels_first':\n","   x_train = x_train.reshape(x_train.shape[0], 1, 41)\n","   x_test = x_test.reshape(x_test.shape[0], 1, 41)\n","   #x_dev = x_dev.reshape(x_dev.shape[0], 1, 41)\n","   input_shape = (1, 41)\n","else:\n","   x_train = x_train.reshape(x_train.shape[0], 41, 1)\n","   x_test = x_test.reshape(x_test.shape[0], 41, 1)\n","   #x_dev = x_dev.reshape(x_dev.shape[0], 41, 1)\n","   input_shape = (41, 1)\n","\"\"\"\n","\n","print(Y_train.shape)\n","print(Y_test.shape)\n","\n","y2_train = Y_train.values.ravel()\n","y2_test  = Y_test.values.ravel()\n","print(y2_train.shape)\n","print(y2_test.shape)\n","\n","\n","#ensemble code\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","\n","\n","from sklearn.svm import SVC\n"," \n","log_clf = LogisticRegression(solver='lbfgs', max_iter=500)\n","rnd_clf = RandomForestClassifier()\n","svm_clf = SVC()\n","nb_clf = GaussianNB()\n","dt_clf = DecisionTreeClassifier(random_state=0) \n","\n","# voting_clf=VotingClassifier(\n","#     estimators=[('lc',log_clf),('rf',rnd_clf,),('svc',svm_clf)],\n","#     voting='soft'\n","# )\n"," \n","voting_clf=VotingClassifier(\n","    estimators=[('lc',log_clf),('dt',dt_clf), ('nv', nb_clf), ('rf',rnd_clf), ('svm',svm_clf)],\n","    # voting='soft'chaoge \n","    voting='soft'\n",")\n","\n","\n","from sklearn.metrics import accuracy_score\n","\n","#y_train = y_train.reshape(y_train.shape[0], 1)\n","#y_train = y_train.iloc[:, 1]\n","#print(\"y shape:\", y_train.shape)\n","#y_train = y_train[0]  #leon\n","#x_test = x_test.reshape(x_test.shape[0], 1, 41)   #leon\n","\n","\n","# for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n","#     clf.fit(X_train,y2_train)\n","#     y_pred=clf.predict(X_test)\n","#     print(clf.__class__.__name__,accuracy_score(y2_test, y_pred))\n","\n","for clf in (log_clf, dt_clf, nb_clf, rnd_clf, svm_clf, voting_clf):\n","#for clf in (log_clf,rnd_clf):\n","    clf.fit(X_train,y2_train)\n","    y_pred=clf.predict(X_test)\n","    print(clf.__class__.__name__,accuracy_score(y2_test, y_pred))\n","\n","\"\"\"\n","\n","model = Sequential()  #sequential序贯模型:多个网络层的线性堆叠\n","#输出的维度（卷积滤波器的数量）filters=32；1D卷积窗口的长度kernel_size=3；激活函数activation   模型第一层需指定input_shape：\n","model.add(Conv1D(32, 3, activation='relu',input_shape=input_shape))  #data_format默认channels_last\n","model.add(MaxPooling1D(pool_size=(2))) #池化层：最大池化  池化窗口大小pool_size=2\n","model.add(Flatten())  #展平一个张量，返回一个调整为1D的张量\n","#model.add(Dropout(0.25))  #需要丢弃的输入比例=0.25    dropout正则化-减少过拟合\n","model.add(Dense(128, activation='relu',name='fully_connected')) #全连接层\n","model.add(Dense(num_classes, activation='softmax',name='softmax'))\n","\n","#编译，损失函数:多类对数损失，用于多分类问题， 优化函数：adadelta， 模型性能评估是准确率\n","model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n","#运行 ， verbose=1输出进度条记录      epochs训练的轮数     batch_size:指定进行梯度下降时每个batch包含的样本数\n","model.fit(x_train, y_train, batch_size= batch_size, epochs=epochs, verbose=1)\n","#history = model.fit(x_train, y_train, batch_size= batch_size, epochs=epochs, verbose=0, validation_data=(x_dev, y_dev))\n","\"\"\"\n","\"\"\"\n","#模型的训练损失（loss）和验证损失（val_loss），以及训练准确率（acc）和验证准确率（val_acc）可以使用绘图代码绘制出来\n","def smooth_curve(points,factor=0.8): #定义使曲线变得平滑\n","    smoothed_points = []\n","    for point in points:\n","        if smoothed_points:\n","            previous = smoothed_points[-1]\n","            smoothed_points.append(previous * factor + point * (1 - factor))\n","        else:\n","            smoothed_points.append(point)\n","    return smoothed_points\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs,loss, 'bo', label = 'Training loss')\n","plt.plot(epochs,val_loss, 'b', label = 'Validation loss')\n","plt.title('Training and validatio loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.figure()\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","plt.plot(epochs, acc,'bo', label = 'Training acc')\n","plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n","plt.title('Training and validatio accuracy')\n","plt.legend()\n","plt.show()\n","\"\"\"\n","\"\"\"\n","# 将测试集输入到训练好的模型中，查看测试集的误差\n","score = model.evaluate(x_test, y_test, verbose=0,batch_size= batch_size)\n","print('Test loss:', score[0])\n","print('Test accuracy: %.2f%%' % (score[1] * 100))\n","\n","#运行的时间\n","stop = time.time()\n","print(str(stop-start) + \"秒\")\n","\n","# 神经网络可视化\n","plot_model(model, to_file='D:/model21.png',show_shapes=True)\n","\n","#输出模型各层参数情况\n","model.summary()\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6ea3a969e225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# y_train = pd.read_csv('train_ye.csv',header=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_2.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_2.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_2.csv'"]}]}]}